{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch_points_kernels as tp\n",
    "from torch.utils.data import DataLoader\n",
    "from torch_points3d.core.common_modules import FastBatchNorm1d\n",
    "from torch_points3d.modules.KPConv.kernels import KPConvLayer\n",
    "from torch_geometric.nn import voxel_grid\n",
    "\n",
    "\n",
    "from lib.pointops2.functions import pointops\n",
    "\n",
    "from util.data_util import collate_fn_limit\n",
    "from util.s3dis import S3DIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = 'cuda:0'\n",
    "cuda_idx = 0\n",
    "device = torch.device(dev)\n",
    "torch.cuda.set_device(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Totally 204 samples in train set.\n"
     ]
    }
   ],
   "source": [
    "data_root = '/home/Pointnet_Pointnet2_pytorch/data/stanford_indoor3d'\n",
    "train_transform = None\n",
    "train_data = S3DIS(split='train', data_root=data_root, test_area=5, voxel_size=0.04, voxel_max=80000,\n",
    "                   transform=train_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, pin_memory=False, \n",
    "                          drop_last=True, collate_fn=partial(collate_fn_limit, max_batch_points=200000, logger=None)\n",
    "                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KPConv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KPConvSimpleBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, prev_grid_size, sigma=1.0, negative_slope=0.2, bn_momentum=0.02):\n",
    "        super().__init__()\n",
    "        self.kpconv = KPConvLayer(in_channels, out_channels, point_influence=prev_grid_size * sigma, add_one=False)\n",
    "        self.bn = FastBatchNorm1d(out_channels, momentum=bn_momentum)\n",
    "        self.activation = nn.LeakyReLU(negative_slope=negative_slope)\n",
    "\n",
    "    def forward(self, feats, xyz, batch, neighbor_idx):\n",
    "        # feats: [N, C]\n",
    "        # xyz: [N, 3]\n",
    "        # batch: [N,]\n",
    "        # neighbor_idx: [N, M]\n",
    "        feats = self.kpconv(xyz, xyz, neighbor_idx, feats)\n",
    "        feats = self.activation(self.bn(feats))\n",
    "        return feats\n",
    "\n",
    "\n",
    "class KPConvResBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, prev_grid_size, sigma=1.0, negative_slope=0.2, bn_momentum=0.02):\n",
    "        super().__init__()\n",
    "        d_2 = out_channels // 4\n",
    "        activation = nn.LeakyReLU(negative_slope=negative_slope)\n",
    "        self.unary_1 = torch.nn.Sequential(nn.Linear(in_channels, d_2, bias=False), FastBatchNorm1d(d_2, momentum=bn_momentum), activation)\n",
    "        self.unary_2 = torch.nn.Sequential(nn.Linear(d_2, out_channels, bias=False), FastBatchNorm1d(out_channels, momentum=bn_momentum), activation)\n",
    "        self.kpconv = KPConvLayer(d_2, d_2, point_influence=prev_grid_size * sigma, add_one=False)\n",
    "        self.bn = FastBatchNorm1d(out_channels, momentum=bn_momentum)\n",
    "        self.activation = activation\n",
    "\n",
    "        if in_channels != out_channels:\n",
    "            self.shortcut_op = torch.nn.Sequential(\n",
    "                nn.Linear(in_channels, out_channels, bias=False), FastBatchNorm1d(out_channels, momentum=bn_momentum)\n",
    "            )\n",
    "        else:\n",
    "            self.shortcut_op = nn.Identity()\n",
    "\n",
    "    def forward(self, feats, xyz, batch, neighbor_idx):\n",
    "        # feats: [N, C]\n",
    "        # xyz: [N, 3]\n",
    "        # batch: [N,]\n",
    "        # neighbor_idx: [N, M]\n",
    "        \n",
    "        shortcut = feats\n",
    "        feats = self.unary_1(feats)\n",
    "        feats = self.kpconv(xyz, xyz, neighbor_idx, feats)\n",
    "        feats = self.unary_2(feats)\n",
    "        shortcut = self.shortcut_op(shortcut)\n",
    "        feats += shortcut\n",
    "        return feats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HOG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_hog(xyz, neighbor_idx):\n",
    "    '''\n",
    "    Histogram of Oriented Gradients in Non-Overlapping Cubic Windows\n",
    "    \n",
    "    1. Query neighbors of all points\n",
    "    2. Reduce each neighborhood by applying SVD\n",
    "    3. Values obtained are s (magnitude) and v[0] (gradient)\n",
    "    4. get angles from gradients & convert angles to unsigned\n",
    "    5. initialize histogram for each cubic window as 2D (zenith & azimuth) array of 9 cells (20 degrees each)\n",
    "    6. each window contributes its gradient to the respective cell of the histogram as per its angles\n",
    "    8. normalize gradients of each window by\n",
    "        (option 1) considering that window only\n",
    "        (option 2) considering 3 adjacent windows\n",
    "    9. flatten the histogram and return it (n, 18)\n",
    "    '''\n",
    "    device = xyz.get_device()\n",
    "    # 1. Query neighbors of all points & get displacement to neighbors\n",
    "    disp = pointops.subtraction(xyz, xyz, neighbor_idx.int())\n",
    "    # 0 distance to itself\n",
    "    disp[neighbor_idx == -1] = 0\n",
    "    # 2. Reduce each neighborhood by applying SVD\n",
    "    _, s, v = np.linalg.svd(disp.cpu().numpy(), full_matrices = False)\n",
    "    # 3. Values obtained are s (magnitude) and v[0] (gradient)\n",
    "    # get the first element (largest variance)\n",
    "    magnitudes = s[:, 0].unsqueeze(-1).cuda(device) # N x 3 -> N x 1\n",
    "    gradients = v[:, :, 0].cuda(device)  #  N x 3 x 3 -> N x 3\n",
    "    # 4. get angles from gradients & convert angles to unsigned\n",
    "    zenith = torch.acos(gradients[:, 2]) * 180 / np.pi\n",
    "    # add 1e-9 for safe division\n",
    "    azimuth = torch.atan(torch.div(gradients[:, 1], gradients[:, 0] + 1e-9)) * 180 / np.pi\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = nn.ModuleList([\n",
    "    KPConvSimpleBlock(6, 48, 0.04, sigma=1.0),\n",
    "    KPConvResBlock(48, 48, 0.04, sigma=1.0)\n",
    "]).cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "offset= tensor([ 43340,  54990,  77996,  88110, 111057, 185809], dtype=torch.int32)\n",
      "offset_= tensor([43340, 11650, 23006, 10114, 22947, 74752], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "max_num_neighbors = 40\n",
    "# (n, 3), (n, c), (n), (b)\n",
    "coord, feat, target, offset = iter(train_loader).next()\n",
    "offset_ = offset.clone()\n",
    "offset_[1:] = offset_[1:] - offset_[:-1]\n",
    "print('offset=', offset)\n",
    "print('offset_=', offset_)\n",
    "batch = torch.cat([torch.tensor([ii]*o) for ii, o in enumerate(offset_)], 0).long()\n",
    "\n",
    "sigma = 1.0\n",
    "radius = 2.5 * 0.04 * sigma\n",
    "neighbor_idx = tp.ball_query(radius, max_num_neighbors, coord, coord, mode=\"partial_dense\", batch_x=batch, batch_y=batch)[0]\n",
    "\n",
    "coord, feat, target, offset, batch, neighbor_idx = coord.cuda(non_blocking=True), feat.cuda(non_blocking=True), \\\n",
    "                                    target.cuda(non_blocking=True), offset.cuda(non_blocking=True), \\\n",
    "                                    batch.cuda(non_blocking=True), neighbor_idx.cuda(non_blocking=True)\n",
    "assert batch.shape[0] == feat.shape[0]\n",
    "feat = torch.cat([feat, coord], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_sample(pos, batch, size, start, return_p2v=True):\n",
    "    # pos: float [N, 3]\n",
    "    # batch: long [N]\n",
    "    # size: float [3, ]\n",
    "    # start: float [3, ] / None\n",
    "\n",
    "    cluster = voxel_grid(pos, batch, size, start=start) #[N, ]\n",
    "\n",
    "    if return_p2v == False:\n",
    "        unique, cluster = torch.unique(cluster, sorted=True, return_inverse=True)\n",
    "        return cluster\n",
    "\n",
    "    unique, cluster, counts = torch.unique(cluster, sorted=True, return_inverse=True, return_counts=True)\n",
    "\n",
    "    # obtain p2v_map\n",
    "    n = unique.shape[0]\n",
    "    k = counts.max().item()\n",
    "    p2v_map = cluster.new_zeros(n, k) #[n, k]\n",
    "    mask = torch.arange(k).cuda().unsqueeze(0) < counts.unsqueeze(-1) #[n, k]\n",
    "    p2v_map[mask] = torch.argsort(cluster)\n",
    "\n",
    "    return cluster, p2v_map, counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "v2p_map, p2v_map, counts = grid_sample(coord, batch, 4, start=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([185809])\n",
      "torch.Size([10, 43340])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "print(v2p_map.shape)\n",
    "print(p2v_map.shape)\n",
    "print(counts.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([43340, 11650, 23006, 10114, 20055,  2892, 28006, 16850, 22413,  7483],\n",
       "       device='cuda:1')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('pt10')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0813755b8afe6c57626065f8754f9d5391594048ab82d14c26059a271a79aa57"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
